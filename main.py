# main.py - å¢å¼ºç‰ˆä¸»ç¨‹åº
import os
import sys
from pathlib import Path
import gradio as gr
from typing import List, Tuple, Dict

# æ·»åŠ srcåˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config import *
from src.core.chat_manager import ChatManager
from src.core.pdf_processor import PDFProcessor
from src.core.document_processor import DocumentProcessor
from src.core.document_analyzer import DocumentAnalyzer
from src.utils.cache_manager import CacheManager
from src.utils.logger import get_logger, logger_manager

# è®¾ç½®æ—¥å¿—
logger_manager.setup_global_logging()
logger = get_logger(__name__)

# å…¨å±€ç®¡ç†å™¨
chat_manager = ChatManager()
pdf_processor = PDFProcessor()
cache_manager = CacheManager()

class AIDocumentAssistant:
    """AIæ–‡æ¡£åŠ©æ‰‹ä¸»ç±»"""
    
    def __init__(self):
        self.current_session = None
        self.loaded_documents = []
        self.qa_chain = None
        self.llm = None
        self.agent = None
        self.document_processor = DocumentProcessor()
        self.document_analyzer = None  # å»¶è¿Ÿåˆå§‹åŒ–
        
    def initialize_system(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        try:
            pdf_dir = Path(PDF_FOLDER)
            pdf_files = list(pdf_dir.glob("*.pdf"))
            
            if pdf_files:
                self.loaded_documents = pdf_processor.process_multiple_pdfs([str(f) for f in pdf_files])
                
                from rag_setup import create_rag_chain
                texts = [doc.page_content for doc in self.loaded_documents]
                self.qa_chain, self.llm = create_rag_chain(texts, MODEL_NAME, OPENAI_API_KEY, base_url=OPENAI_API_BASE)
                
                from agent_setup import create_agent
                from tools import get_tools
                tools = get_tools(self.qa_chain, SERPAPI_KEY)
                self.agent = create_agent(tools, self.llm)
                
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def chat_with_ai(self, message: str, history: List[Dict[str, str]], session_id: str) -> Tuple[List[Dict[str, str]], str]:
        """ä¸AIå¯¹è¯ï¼Œæ™ºèƒ½ä¼˜å…ˆä»çŸ¥è¯†åº“æ‰¾ç­”æ¡ˆï¼Œæ‰¾ä¸åˆ°å†ç”¨å¤§æ¨¡å‹å›å¤"""
        try:
            if not message.strip():
                return history, session_id
            
            if not session_id or session_id not in chat_manager.sessions:
                session_id = chat_manager.create_session(f"å¯¹è¯_{len(chat_manager.sessions) + 1}")
            
            cache_key = f"{message}_{session_id}"
            cached_response = cache_manager.get(cache_key)
            
            if cached_response:
                response = cached_response
            else:
                # ä¼˜å…ˆå°è¯•ä»çŸ¥è¯†åº“è·å–ç­”æ¡ˆ
                knowledge_response = None
                if self.agent and self.loaded_documents:
                    try:
                        # ä½¿ç”¨çŸ¥è¯†åº“æŸ¥è¯¢
                        chinese_prompt = f"è¯·åŸºäºå·²ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹ï¼Œç”¨ä¸­æ–‡å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{message}"
                        knowledge_response = self.agent.run(chinese_prompt)
                        
                        # æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦æœ‰æœ‰æ•ˆå›ç­”
                        if not knowledge_response or len(knowledge_response.strip()) < 10 or "æ‰¾ä¸åˆ°" in knowledge_response or "æœªæ‰¾åˆ°" in knowledge_response:
                            knowledge_response = None
                    except Exception as e:
                        logger.warning(f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {e}")
                        knowledge_response = None
                
                # å¦‚æœçŸ¥è¯†åº“æ²¡æœ‰ç­”æ¡ˆï¼Œä½¿ç”¨å¤§æ¨¡å‹é€šç”¨å›å¤
                if knowledge_response:
                    response = knowledge_response
                else:
                    try:
                        # ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œé€šç”¨å›å¤
                        if self.llm:
                            general_prompt = f"è¯·ç”¨ä¸­æ–‡å›ç­”è¿™ä¸ªé—®é¢˜ï¼š{message}"
                            response = self.llm.invoke(general_prompt).content
                        else:
                            # å¦‚æœæ²¡æœ‰åˆå§‹åŒ–LLMï¼Œä½¿ç”¨é»˜è®¤å›å¤
                            response = "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
                    except Exception as e:
                        logger.error(f"å¤§æ¨¡å‹å›å¤é”™è¯¯: {e}")
                        response = "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè¯·ç¨åå†è¯•"
                
                # ç¼“å­˜å›å¤
                if not cache_manager.get(cache_key):
                    cache_manager.set(cache_key, response, ttl=3600)
            
            chat_manager.add_message(session_id, "user", message)
            chat_manager.add_message(session_id, "assistant", response)
            
            return chat_manager.get_chat_history(session_id), session_id
            
        except Exception as e:
            logger.error(f"èŠå¤©é”™è¯¯: {e}")
            error_message = "æŠ±æ­‰ï¼Œç³»ç»Ÿé‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•"
            chat_manager.add_message(session_id, "user", message)
            chat_manager.add_message(session_id, "assistant", error_message)
            return chat_manager.get_chat_history(session_id), session_id
    
    def upload_and_process_files(self, files: List[str]) -> str:
        """ä¸Šä¼ å¹¶å¤„ç†å¤šç§æ ¼å¼çš„æ–‡ä»¶"""
        if not files:
            return "æ²¡æœ‰æ–‡ä»¶è¢«ä¸Šä¼ "
        
        from src.core.document_processor import DocumentProcessor
        
        doc_processor = DocumentProcessor()
        results, new_documents = [], []
        
        for file_path in files:
            try:
                file_path = Path(file_path)
                
                # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
                if file_path.suffix.lower() not in doc_processor.supported_formats:
                    results.append(f"âŒ {file_path.name} - ä¸æ”¯æŒçš„æ ¼å¼: {file_path.suffix}")
                    continue
                
                # å¤„ç†æ–‡æ¡£
                documents = doc_processor.process_document(str(file_path))
                new_documents.extend(documents)
                
                # è·å–æ–‡æ¡£ä¿¡æ¯
                info = doc_processor.get_document_info(str(file_path))
                results.append(f"âœ… {info['filename']} - {info['format']}æ ¼å¼, {info['size']}, {info['pages']}")
                
            except Exception as e:
                results.append(f"âŒ {os.path.basename(file_path)} - å¤„ç†å¤±è´¥: {str(e)}")
        
        if new_documents:
            self.loaded_documents.extend(new_documents)
            self._recreate_rag_chain()
        
        return "\n".join(results)
    
    def _recreate_rag_chain(self):
        """é‡æ–°åˆ›å»ºRAGé“¾"""
        from rag_setup import create_rag_chain
        from agent_setup import create_agent
        from tools import get_tools
        from src.core.pdf_processor import PDFProcessor
        
        pdf_files = list(Path(PDF_FOLDER).glob("*.pdf"))
        processor = PDFProcessor()
        self.loaded_documents = processor.process_multiple_pdfs([str(f) for f in pdf_files])
        texts = [doc.page_content for doc in self.loaded_documents]
        self.qa_chain, self.llm = create_rag_chain(texts, MODEL_NAME, OPENAI_API_KEY, base_url=OPENAI_API_BASE)
        tools = get_tools(self.qa_chain, SERPAPI_KEY)
        self.agent = create_agent(tools, self.llm)

    def search_in_documents(self, keyword: str) -> str:
        """åœ¨æ–‡æ¡£ä¸­æœç´¢"""
        if not keyword.strip():
            return "è¯·è¾“å…¥æœç´¢å…³é”®è¯"
        
        try:
            pdf_files = list(Path(PDF_FOLDER).glob("*.pdf"))
            if not pdf_files:
                return "æŠ±æ­‰ï¼Œå½“å‰æ²¡æœ‰ä»»ä½•PDFæ–‡æ¡£å¯ä¾›æœç´¢ï¼Œè¯·å…ˆä¸Šä¼ æ–‡æ¡£"
            
            results = pdf_processor.search_pdfs_by_keyword([str(f) for f in pdf_files], keyword)
            if not results:
                return f"æŠ±æ­‰ï¼Œåœ¨æ–‡æ¡£ä¸­æ²¡æœ‰æŸ¥è¯¢åˆ°åŒ…å« '{keyword}' çš„ç›¸å…³å†…å®¹ï¼Œè¯·å°è¯•ä½¿ç”¨å…¶ä»–å…³é”®è¯"
            
            return "\n\n".join([
                f"ğŸ“„ {r['filename']} - ç¬¬{r['page']}é¡µ ({r['occurrences']}å¤„åŒ¹é…)\né¢„è§ˆ: {r['preview']}"
                for r in results
            ])
            
        except Exception as e:
            logger.error(f"æœç´¢é”™è¯¯: {e}")
            return "æŠ±æ­‰ï¼Œæœç´¢æ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•"

    def analyze_single_document(self, file) -> tuple:
        """åˆ†æå•ä¸ªæ–‡æ¡£"""
        try:
            if not file:
                return {}, "è¯·å…ˆä¸Šä¼ æ–‡æ¡£", ""
            
            # ç¡®ä¿LLMå·²åˆå§‹åŒ–
            if not self.llm:
                from rag_setup import create_rag_chain
                texts = ["ä¸´æ—¶åˆå§‹åŒ–ç”¨äºæ–‡æ¡£åˆ†æ"]  # ä¸´æ—¶æ–‡æœ¬ç”¨äºåˆå§‹åŒ–LLM
                _, self.llm = create_rag_chain(texts, MODEL_NAME, OPENAI_API_KEY, base_url=OPENAI_API_BASE)
                self.document_analyzer = DocumentAnalyzer(self.llm)
            elif not self.document_analyzer:
                self.document_analyzer = DocumentAnalyzer(self.llm)
            
            # å¤„ç†æ–‡æ¡£
            documents = self.document_processor.process_file(file.name)
            if not documents:
                return {}, "æ— æ³•å¤„ç†è¯¥æ–‡æ¡£", ""
            
            # åˆ†ææ–‡æ¡£
            analysis = self.document_analyzer.analyze_document(documents)
            
            # æ ¼å¼åŒ–è¾“å‡º
            summary = analysis.get("æ‘˜è¦", "")
            keywords_html = "<div>"
            for keyword in analysis.get("å…³é”®è¯", [])[:10]:
                keywords_html += f"<span style='background: #e3f2fd; padding: 3px 8px; margin: 2px; border-radius: 12px; display: inline-block;'>{keyword}</span>"
            keywords_html += "</div>"
            
            return analysis, summary, keywords_html
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£åˆ†æå‡ºé”™: {e}")
            return {}, f"åˆ†æå‡ºé”™: {str(e)}", ""
    
    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢ - ä½¿ç”¨æ–°çš„ç•Œé¢æ¨¡å—"""
        from src.ui.interface import AIDocumentInterface
        ui = AIDocumentInterface(self)
        return ui.create_interface()

# åˆ›å»ºå…¨å±€å®ä¾‹
assistant = AIDocumentAssistant()

if __name__ == "__main__":
    try:
        # ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤ç«¯å£7860
        import os
        port = int(os.getenv("GRADIO_SERVER_PORT", "7860"))
        
        # è·å–æœ¬æœºIPåœ°å€
        import socket
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        
        print("=" * 50)
        print("AIæ–‡æ¡£é—®ç­”ç³»ç»Ÿå¯åŠ¨ä¸­...")
        print("=" * 50)
        print(f"æœ¬åœ°è®¿é—®: http://localhost:{port}")
        print(f"å±€åŸŸç½‘è®¿é—®: http://{local_ip}:{port}")
        print("å¦‚éœ€ä¿®æ”¹ç«¯å£ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ GRADIO_SERVER_PORT")
        
        assistant.create_interface().launch(
            server_name="0.0.0.0",  # ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£
            server_port=port, 
            show_error=True,
            share=False  # å…³é—­Gradioçš„åˆ†äº«åŠŸèƒ½ï¼Œä½¿ç”¨æœ¬åœ°ç½‘ç»œ
        )
    except OSError as e:
        if "Cannot find empty port" in str(e):
            logger.warning(f"ç«¯å£{port}è¢«å ç”¨ï¼Œå°è¯•ä½¿ç”¨éšæœºç«¯å£")
            new_port = port + 1
            print(f"ç«¯å£{port}è¢«å ç”¨ï¼Œå°è¯•ä½¿ç”¨ç«¯å£{new_port}")
            assistant.create_interface().launch(
                server_name="0.0.0.0", 
                server_port=new_port, 
                show_error=True,
                share=False
            )
        else:
            logger.error(f"å¯åŠ¨å¤±è´¥: {e}")
            raise
    except Exception as e:
        logger.error(f"å¯åŠ¨å¤±è´¥: {e}")
        raise


